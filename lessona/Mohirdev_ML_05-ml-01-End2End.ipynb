Machine Learning qanday ishlashini tushunish uchun ushbu darsimiz davomida biz bitta loyihani boshidan oxirigacha birgalikda qilamiz. 

Dars davomida tushunmagan mavzularga duch kelsangiz, havotir qilmang, kurs davomida juda ko'p masalalarga qayta to'xtalamiz.

### 1-QADAM. FAOLIYATNI O'RGANISH

Keling boshlanishiga loyiha haqida tasavvur hosil qilaylik.

Sizning buyurtmachingiz "California Inc" Qurilish Kompaniyasi. Kompaniya keyingi uylarini qurishda California shtatining turli hududlarida uylarning o'rtacha narxini hisoblab beruvchi model (dastur) yaratishni so'rayapti.

Sizga berilgan ma'lumotlar: California shtatida aholini ro'yxatga olish uchun o'tkazilgan so'rovnoma natijasi.

Ma'lumotlar Californianing har bir hududi (__blok__ deb ataladi) uchun aholi soni, aholining median daromadi, uylarning median narxi kabi qiymatlarni o'z ichiga oladi. Har bir hududda tahminan 600 dan 3000 gacha aholi yashaydi.

**Demak sizning vazifangiz yuqorida ma'lumotlarga asoslangan holda turli hududlarda uylarning median narxini aniqlab beruvchi model (dastur) yaratish**

#### 1.1 Jarayonlarni tushunish

Sizning birinchi qiladigan ishingiz, loyiha haqida ko'proq ma'lumot to'plash. Bu sizga loyihaga to'g'ri yondoshish, to'g'ri model tanlash, qanday algoritmlardan foydalanishni aniqlash uchun yordam beradi. 

Misol uchun, birinchi savol: Ushbu model qayerda ishlatiladi?
Buyurtmachi sizning modelingdan qaytgan natija boshqa, siz bilmaydigan, ma'lumotlar bilan birgalikda yana boshqa modelning kirishiga ulanishini va yakuniy model ko'rsatilgan hududga investisiya kiritish yoki kiritmaslik haqida qaror qabul qilishini aytdi. 

Demak, sizning modelingiz kattaroq modelga ulanar ekan. 

Keyingi savol: Hozirda buyurtmachi median narxni aniqlashda qanday usuldan foydalanayapti va joriy usulning aniqligi nechiga teng, uning kamchiliklari nimada?

Javob: Hozirda hudud uchun narxlar bir nechta mutaxassislarning tahliliga asosan, qo'lda aniqlanmoqda. Aniqligi 20%. 

Mana endi keyingi bosqichga o'tamiz.

#### 1.2 Analitik yondoshuvni aniqlash
Bu bosqichda biz bir nechta narsalarni aniqlashtirib olamiz: 
- Model: Supervised, Unsupervised, Reinforcement?
- Algoritm: klassifikasiya, regressiya, yoki boshqa turda
- Usul: Online yoki offline

Yuqoridagi savollarga javob beramiz:
1. Supervised learning - sababi bizda ma'lumotlarda label (yorliq) mavjud. Bu hududdadi median narx. Biz ham aynan shu narxni bashorat qilmoqchimiz.
2. Regressiya - "Bashorat" (prognoz) dedikmi demak bu regressia algoritmlari yordamida hal qilinadi
3. Offline - sababi ma'lumotlar bizga avvaldan bir marta berilgan. Doimiy ma'lumotlar oqimi yo'q.

Model aniqligini qanday baholaymiz?

Aniqlikni baholashning turli usullari bor, regressiya algoritmlar uchun odatda **o'rtacha kvadrat xatolik** (Root Mean Square Error - RMSE) ko'p ishlatiladi:

![RMSE](https://i.imgur.com/aXL9iWa.png)

Bu yerda:
- $m$ - datasetdagi qatorlar soni (har bir qator bitta ma'lumot)
- $x^{(i)}$ - $i$-qator uchun barcha parametrlar vektori (_label_ dan tashqari)
- $y^{(i)}$ - $i$-qator uchun label (bizdagi misolda median uy narxi)
- $X$ - labeldan boshqa barcha parametrlar
- $h$ - sizning modelingizdan qaytgan bashorat (hypothesis). 
    - $h(x^{(i)})$ - $i$-qator uchun model qaytargan bashorat.
    
Aniqlikni baholashning yana bir usuli, o'rtacha absolyut xatolik (mean absolute error - MAE).

![MAE](https://i.imgur.com/GJH9CGy.png)

RMSE ham MAE ham ikki vektor, bashorat va label o'rtasidagi farqni hisoblaydi. Xato qancha kam bo'lsa, natija shuncha yaxshi hisoblanadi.

Keyingi bosqichga o'tishdan avval, yuqoridagi xulosalarimizni tasdiqlab olamiz. Sababi, sizning regressiya modelingiz aniq son qaytaradi (uyning bashorat qilingan narxi), lekin buyurtmachi sizdan son emas "qimmat", "arzon", "o'rtacha" kabi qiymatlarni kutgan edi. Bu esa klassifikasiya algoritmi yordamida hal qilinishi kerak edi. Demak, siz modelingizdan qaytadigan natija buyurtmachi kutgan natija bilan bir ekanini aniqlashtirib olamiz.

### 2-QADAM. MA'LUMOTLARNI O'RGANAMIZ

#### !DIQQAT. Keyingi qadamlarni bajarishdan avval, loyiha uchun yangi muhit yaratib olish tavsiya qilinadi. Umuman olganda har bir loyiha uchun alohida muhit yaratish yaxshi odat!


<img src="https://i.imgur.com/YcFHBRK.png" alt="Anaconda" width="800"/>

Kerakli modullarni chaqirib olamiz. Bu safar bizga avvaldan tanish `pandas`, `numpy` kutubxonalaridan tashqari, yangi, `scikit-learn` kutubxonaisini ham chaqiramiz. 

**[scikit-learn](https://scikit-learn.org/stable/)** - turli Machine Learning algoritmlarni jamlagan kutubxona bo'lib, kelgusida ishimizni bir necha bor osonlashtiradi. 

import pandas as pd
import numpy as np
import sklearn # scikit-learn kutubxonasi
import matplotlib.pyplot as plt
import seaborn as sns

# Onlayn dataset joylashgan manzilini ko'rsatamiaz
URL = "https://github.com/ageron/handson-ml2/blob/master/datasets/housing/housing.csv?raw=true"
df = pd.read_csv(URL)
df.head()

Datasetning har bir qatori bu bitta hudud (mahalla, kvartal, blok) haqida ma'lumot. Dataset 10 ta ustundan iborat:
- `longitude` va `latitude` birgalikda GPS koordinatalar
- `housing_median_age` - uylarning median yoshi
- `total_rooms` - ushbu hududda mavjud jami xonalar
- `total_bedrooms` - ushbu hududda mavjud jami yotoqxonalar
- `population` - hudud aholi soni
- `households` - hududdagi oilalar soni
- `median_income` - median daromad
- `median_house_values` - uylarning median narxi
- `ocean_proximity` - hududning okeanga qanchalik yaqinligi

### ‚ùì Median va o'rtacha qiymatlar o'rtasida farqni bilasizmi? 

Deylik bizda 10 ta son bor, shu sonlarning o'rtachasini hisoblash uchun avval ularni qo'shamiz keyin esa yig'indini 10 ga bo'almiz.
Median hisoblash uchun esa sonlarni o'sish tartibida tahlaymiz va o'rtadagi sonni olamiz.

![Imgur](https://i.imgur.com/Qkzwv3u.png)

### 2.1 Ma'lumotlarni ko'ramiz qilamiz

df.info()

Yuqoridagi natijadan olingan xulosalar:
1. Dataset 20640 qatordan iborat (har bir qator bu alohida hudud (blok, mahalla, kvartal))
2. `total_bedrooms` ustunida ma'lumotlar to'liq emas (20433 qator to'liq, qolgan 207 tasida ma'lumot yo'q)
3. `ocean_proximity` ustunidan boshqa barcha ustunlar sonli.

`ocean_proximity` ustunini ko'ramiz:

df['ocean_proximity'].value_counts()

Demak bu ustunda uylarning okeandan qanchalik uzoqligi matn ko'rinishida saqlangan. Har bir matnni tarjima qilishni sizga vazifa qilib qoldiramiz. 
Biz esa ma'lumotlarni tahlil qilishda davom etamiz.

df.describe()

Yuqoridagi jadvladan qanday xulosalar oldingiz?

Ma'lumotlarni tahlil qilishning yana bir usuli - vizualizasiya

%matplotlib inline
df.hist(bins=50, figsize=(20,15))
plt.show()

Tahlilda davom etamiz:
1. `median_income` (median daromad) - ustunidagi sonlar tushunarsiz (1 xonali son nimani anglatadi?). Mijoz bilan gaplashgandan so'ng sonlar ming dollarda ekanini bilamiz (ya'ni 4 bu 4000$ degan)
2. `housing_median_age` (uylarning median yoshi) grafikida 50 yoshli uylar birdan oshib ketgan. Mijozda bilan buni aniqlashtiramiz: ma'lumotlar jamlanganda yoshi 50 dan oshgan barcha uylar 50 deb kiritilgan ekan (orasida 60-70-100 yillik ular ham bo'lishi mumkin). Ya'ni ma'lumotlarga chegara belgilangan. 
3. `median_house_value` (uylarning median narhi) da ham shunday holat, ya'ni narhi 500 000\$ dan qimmat uylar hammasi 500ming deb yozib yuborilgan. **Bu esa biz uchun yaxshi emas**. Sababi, bizning qurgan modelimiz 500mingdan qimmat uylarni to'g'ri baholay olmaydi. Oldimizda 2 yo'l bor:
    - Qimmat uylar uchun ma'lumotlarni qayta yig'ish
    - 500mingdan qimmat uylar bor hududlarni datasetdan chiqarib tashlash.
4. Ma'lumotlar taqsimoti bir tomonga og'gan (qo'ng'iroqsimon emas), ML uchun normal taqsimot bo'lgani afzal (buni qanday to'g'rilashni kelgusida ko'ramiz).
![normal taqsimot](https://miro.medium.com/max/1200/1*IdGgdrY_n_9_YfkaCh-dag.png)

### 2.2 Trains va Test set.
Esingizda bo'lsa avvalgi modulda ML uchun ma'lumotlarni ikki (aniqro'gi uch) qismga ajratib olishni gaplashgan edik: 
- Train set - model yaratish uchun
- Test set - model aniqligini tekshirish uchun

Aslida, ma'lumotlarni tahlil qilish bosqichida bunga hali ertadek tuyulishi mumkin, lekin bu yerda maqsad nafaqat komyuterni balki bizning ham xato xulosa qilishimizni oldini olish.

Avval tasviya qilganimizdek ma'lumotlarnining 80\% train, 20\% test uchun ajratamiz. Buning uchun `scikit-learn` tarkibida tayyor `train_test_split` funskyasiga murojaat qilamiz.

Funskiyaga parametr sifatida dataset (`df`), test set hajmi (0.2 ya'ni 20%) va tasodifiy sonlar generatori uchun qiymat (`random_seed`) beramiz.

**`random_seed`** ning vazifasi `train_test_split` funksiyani ishga tushirganda doim bir hil tasodifiy qiymatlar olish. Bu esa, ML model yaratish jarayonida `test_set` doim yashirin qolishini ta'minlaydi.

from sklearn.model_selection import train_test_split
train_set, test_set = train_test_split(df, test_size=0.2, random_state=42)

train_set

test_set.shape

`train_test_split` yordamida bo'lishning kamchiligi, ma'lumotlardagi balans yo'qolishi mumkin. Misol uchun, bizdagi datasetda `median_income` ustuniga qarasak aholining aksari 2000-4000\$ oralig'da daromad qilar ekan. 8000 dan ko'proq daromad oladiganlar esa anchagina kam. Agar biz train va test setlarda shu taqisomtni saqlab qolmoqchi bo'lsak `StratifiedShuffleSplit` obyektiga murojaat qilamiz.

%matplotlib inline
df['median_income'].hist(bins=50, figsize=(9,6))
plt.show()

`StratifiedShuffleSplit`dan foydalanishdan avval `median_income` ustunidagi qiymatlarni bir nechta kategoriyalarga ajratib olishimiz kerak. Aynan shu kategoriyalar `StratifiedShuffleSplit` ichidagi split funksiyasiga uzatiladi va funksiya shu kategoriya asosida train va test set o'rtasidagi balansni saqlaydi.

df['income_cat'] = pd.cut(df['median_income'], bins=[0., 1.5, 3.0, 4.5, 6.0, np.inf], labels=[1,2,3,4,5])
df['income_cat'].hist(figsize=(9,6))
plt.show()

from sklearn.model_selection import StratifiedShuffleSplit
stratified_split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)
# stratified_split.split funksiyasi indekslar qaytaradi
for train_index, test_index in stratified_split.split(df,df['income_cat']):
    strat_train_set = df.loc[train_index]
    strat_test_set = df.loc[test_index]

`income_cat` ustuni endi kerak emas, train va test setlardan o'chirib tashlaymiz.

strat_train_set.drop('income_cat', axis=1, inplace=True)
strat_test_set.drop('income_cat', axis=1, inplace=True)

### 2.3 Ma'lumotlarni tahlil qilamiz.

Keling endi bevosita ma'lumotlarni tahlil qilishga o'taylik. Esingizda bo'lsa biz endi `train` set bilan ishlashimiz kerak. Bizda hozircha 2 ta alohida train set bo'lib qoldi:
- `train_set` - `train_test_split` yordamida bo'lingan (muvozanatsiz)
- `strat_train_set` - `StratifiedShuffleSplit` yordamida bo'lingan.

Biz ikkinchi setdan foydalanamiz. Qulaylik uchun bu setimizda nusxa ko'chirib olamiz.

housing = strat_train_set.copy()

### Vizualziasiya
Ma'lumotlarni tahlil qilishning eng qulay usuli bu grafiklar. Keling boshlanishiga uylarning geografik joylashuvini ko'ramiz.

Tushunarli bo'lishi uchun, Kalifronia shtati xaritasini ham chiqaramiz:

<img src="https://www.nationsonline.org/maps/USA/California_map.jpg" alt="California" width="600"/>

housing.plot(kind="scatter", x="longitude", y="latitude", figsize=(9,6))
plt.show()

Yaxshi, lekin bu ko'rinihsda ko'p ma'lumot ololmaymiz. Yagona xulosamiz, okeanga yaqin aholi zichroq ekan.

Keling grafikka biroz ma'no beramiz.

housing.plot(
    kind="scatter", 
    x="longitude", 
    y="latitude", 
    alpha=0.4,
    s=housing['population']/100, # nuqta radiusi aholi soniga qarab o'zgaradi
    label="population",
    c="median_house_value", # nuqta rangi uyning narxiga qarab o'zgaradi
    cmap="jet", # ranglar. Ko'k - daromadi kam, qizil - daromadi ko'p
    colorbar=True,
    figsize=(10,8)
)
plt.show()

Bunisi ancha yaxshiroq. Grafikdon qanday xulosalar olishimiz mumkin?
- Okeanga yaqin joylarda uylarning ham narxi qimmatroq
- Okeanga yaqin hududlarda aholi zichroq

### Korrelyasiya
Bizning asl maqsadimiz bizga berilgan ma'lumotlar orasida uyning narxiga ta'sir qiluvchi parametrlarni topish. Bunda esa bizga aynan korrelyasiya juda qo'l keladi.

Korrelysasiya haqida biz Data Analysis kursimizda batafsil to'xtalganmiz.

housing.corrwith(housing['median_house_value']).sort_values(ascending=False)

Ko'rishimiz mumkinki, `median_house_value` va `median_income`, `total_rooms`, `housing_median_age` ustunlari orasida korrelyatsiya nisbatan kuchli.

`seabron` tarkibidagi `pairplot` funksiyasi yordamida korrelyasiya qiymatlarini grafik ko'rinishida chiqarishimiz ham mumkin.

cols = ['median_house_value','median_income','total_rooms','housing_median_age']
sns.pairplot(housing[cols], height=5)
plt.show()

Barcha ustunlar orasida `median_income` va uy narxi o'rtasida korrelyatsiya eng kuchli ekan, keling uni alohida chizaylik.

housing.plot(kind='scatter', x="median_income", y="median_house_value", alpha=0.1, figsize=(9,7))
plt.show()

Grafikda kuchli korrelyasiya borligini ko'rishimiz mumkin. Ya'ni hudud bo'yicha aholining daromadi oshgani sari, hududdagi narxlar ham oshgan. 

LEKIN, avval aytganimizdek 500,000\$ dan qimmat uylar 500mingda  chegaralab qo'yilgan. Undan tashqari 350ming va 450ming atrofida ham shunday chegarani ko'rishimiz mumkin (seizlar-sezilmas gorizontal chiziq).

Keyingi bosqichlarda bu qiymatlarni olib tashlashimiz kerak bo'ladi. Aks holda modelimiz ham xato ishlaydi.

### 2.4 Yangi parametrlar yaratamiz

Yuqorida `median_income` uylarning median bahosini topish uchun yaxshi parametr ekanini ko'rdik, lekin bu parametrning o'zi yetarli emas. Shunday holatlarda ba'zi parametrlani jamlab yangi parametrlar hosil qilishimiz mumkin.

Misol uchun, hududdagi jami xonalar soni (`total_rooms`) unchalik ham muhim emas, lekin jami xonalar sonini jami xonadonlar (`households`) soniga bo'lsak har bir xonadon uchun o'rtacha xonalar soni chiqadi (ya'ni har bir uyning o'rtacha xonalari soni) bu esa uyning bahosini aniqlashda muhim bo'lishi mumkin.

housing['rooms_per_household'] = housing['total_rooms']/housing['households']
housing["bedrooms_per_room"] = housing["total_bedrooms"]/housing["total_rooms"]
housing["population_per_household"]=housing["population"]/housing["households"]

housing.corrwith(housing['median_house_value']).sort_values(ascending=False)

